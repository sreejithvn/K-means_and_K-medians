{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "jzhTuyxUbeIf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "# SEED = np.random.randint(100)\n",
    "np.random.seed(53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "id": "aW5sfezMbxDO"
   },
   "outputs": [],
   "source": [
    "animals = pd.read_csv('CA2Data/animals', header=None, delimiter=' ')\n",
    "countries = pd.read_csv('CA2Data/countries', header=None, delimiter=' ')\n",
    "fruits = pd.read_csv('CA2Data/fruits', header=None, delimiter=' ')\n",
    "veggies = pd.read_csv('CA2Data/veggies', header=None, delimiter=' ')\n",
    "# Assign numerical 'category' values corresponding to true labels\n",
    "animals[0] = 0\n",
    "countries[0] = 1\n",
    "fruits[0] = 2\n",
    "veggies[0] = 3\n",
    "\n",
    "dataset = pd.concat([animals, countries, fruits, veggies], ignore_index=True)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327,)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store category data to compute metrics\n",
    "category = np.array(dataset[0])\n",
    "# category = np.array(dataset[0]).reshape(-1,1)\n",
    "category.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop category column\n",
    "dataset.drop(columns=[0], inplace=True)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YeCXwoSQg7wp",
    "outputId": "4eca887a-e25c-4bb9-897b-e8e5b2ec954c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 300)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(dataset)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# K-mean * K-medians\n",
    "\n",
    "def euclidean_distance(X,Y):\n",
    "    # Return the Euclidean distance between X and Y\n",
    "    # return np.sqrt(np.sum((X-Y)**2))\n",
    "    return np.linalg.norm(X-Y)\n",
    "\n",
    "\n",
    "def manhattan_distance(X,Y):\n",
    "    # Return the Manhattan distance between X and Y\n",
    "    # return np.abs(X-Y).sum()\n",
    "    return np.sum(np.abs(X-Y))\n",
    "\n",
    "\n",
    "def check_convergence(k_means, k_medians):\n",
    "    # if k_means:\n",
    "    #     np.sum()\n",
    "    pass\n",
    "\n",
    "\n",
    "def group_data_to_cluster(num_centroids):\n",
    "    # Initialise 'clusters', to later store the centroid index value to the corresponding datapoint index\n",
    "    clusters = np.zeros((len(dataset), 1))\n",
    "    num_datapoints = len(dataset)\n",
    "\n",
    "    # loop through each datapoint\n",
    "    for index in range(num_datapoints):\n",
    "        # Initialise 'distances', to store the 'distance' value from each centroid to the datapoint\n",
    "        distances = np.zeros((num_centroids, 1))\n",
    "        # Loop through each centroid\n",
    "        for centroid_index in range(num_centroids):\n",
    "            if k_means:\n",
    "                # for k-means, find the eucledian distance from the datapoint to each centroid\n",
    "                distance_to_centroid = euclidean_distance(dataset[index], centroids[centroid_index])\n",
    "                # update the 'distance' value to the 'distances' array\n",
    "                distances[centroid_index] = distance_to_centroid\n",
    "\n",
    "            elif k_medians:\n",
    "                # for k-medians, find the manhattan distance from the datapoint to each centroid\n",
    "                distance_to_centroid = manhattan_distance(dataset[index], centroids[centroid_index])\n",
    "                # update the 'distance' value to the 'distances' array\n",
    "                distances[centroid_index] = distance_to_centroid\n",
    "\n",
    "        # Get the closest centroids index value\n",
    "        closest_centroid_index = np.argmin(distances)\n",
    "        # Assign the closest centroid index value to the corresponding datapoint index (in the 'clusters' array)\n",
    "        clusters[index] = closest_centroid_index\n",
    "#     print(clusters)\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def update_centroids(clusters, num_centroids):\n",
    "    # Iterate over the centroids, to update them based on the updated cluster data\n",
    "    for centroid_index in range(num_centroids):\n",
    "        if k_means:\n",
    "            # Compute the mean of datapoints for each cluster, and set them as the new centroids\n",
    "            centroids[centroid_index] = np.mean(data[clusters.flatten() == centroid_index], axis=0)\n",
    "        elif k_medians:\n",
    "            # Compute the median of datapoints for each cluster, and set them as the new centroids\n",
    "            centroids[centroid_index] = np.median(data[clusters.flatten() == centroid_index], axis=0)\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def compute_metrics(k):\n",
    "    num_datapoints = len(data)\n",
    "    print(num_datapoints)\n",
    "    precision = np.zeros((num_datapoints))\n",
    "    recall = np.zeros((num_datapoints))\n",
    "    f_score = np.zeros((num_datapoints))\n",
    "    for index in range(num_datapoints):\n",
    "        # get the count of the 'category' from it's assigned 'cluster'\n",
    "        category_in_cluster_count = np.count_nonzero(cat[clust==clust[index]] == cat[index])\n",
    "        # get the total count of datapoints belonging to the 'category' in the dataset\n",
    "        category_total_count = np.count_nonzero(cat==cat[index])\n",
    "        # get the count of datapoints assigned to the 'cluster'\n",
    "        cluster_elements_count = np.count_nonzero(clust == clust[index])\n",
    "    #     count = np.sum(cat[clust==clust[index]]==cat[index])\n",
    "        # compute precision\n",
    "        precision[index] = category_in_cluster_count / cluster_elements_count\n",
    "        recall[index] = category_in_cluster_count / category_total_count\n",
    "    #     f_score[index] = 2*precision[index]*recall[index]/(precision[index]+recall[index])\n",
    "    #     print(f'Count of category {cat[index]} in cluster {clust[index]} = {category_in_cluster_count}')\n",
    "    #     print(f'Count of category {cat[index]} in dataset = {category_total_count}')\n",
    "    #     print(f'Total elements in cluster {clust[index]} = {cluster_elements_count}')\n",
    "    f_score = 2*precision*recall/(precision+recall)\n",
    "    print(precision)\n",
    "    print(recall)\n",
    "    print(f_score)\n",
    "    precision = np.sum(precision)/num_datapoints\n",
    "    recall = np.sum(recall)/num_datapoints\n",
    "    f_score = np.sum(f_score)/num_datapoints\n",
    "    print(precision)\n",
    "    print(recall)\n",
    "    print(f_score)\n",
    "    return precision, recall, f_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial centroids\n",
      " [[ 0.52242  -0.14079  -0.096228 ... -0.43478   0.86687   0.045675]\n",
      " [-0.15919   0.13402  -0.60023  ... -0.51513  -0.31658   0.25369 ]\n",
      " [ 0.12423  -0.063348  0.25331  ... -0.7498   -0.073445 -0.011316]\n",
      " [ 0.44003   0.41338  -0.3769   ...  0.16981   0.022406  0.48342 ]]\n",
      "327\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9g/_31yc5b92m96cxdj9hkt6kd80000gn/T/ipykernel_2995/2546957356.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_centroids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_centroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_centroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nKMeans Centroids from computed for k = 4:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9g/_31yc5b92m96cxdj9hkt6kd80000gn/T/ipykernel_2995/3388045427.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_datapoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# get the count of the 'category' from it's assigned 'cluster'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mcategory_in_cluster_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclust\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mclust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;31m# get the total count of datapoints belonging to the 'category' in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mcategory_total_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "SEED = np.random.randint(100)\n",
    "np.random.seed(53)\n",
    "# print(SEED)\n",
    "# 53, 40, 18\n",
    "\n",
    "# import data\n",
    "data1 = pd.read_csv('CA2Data/animals', header=None, delimiter=' ')\n",
    "data2 = pd.read_csv('CA2Data/countries', header=None, delimiter=' ')\n",
    "data3 = pd.read_csv('CA2Data/fruits', header=None, delimiter=' ')\n",
    "data4 = pd.read_csv('CA2Data/veggies', header=None, delimiter=' ')\n",
    "# dataset = pd.concat([data1, data2, data3, data4])\n",
    "\n",
    "# concatenate data points\n",
    "dataset = pd.concat([data1.iloc[:,1:], data2.iloc[:,1:], data3.iloc[:,1:], data4.iloc[:,1:]])\n",
    "\n",
    "# convert data set to numpy array\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "# choose 'k' for number of clusters \n",
    "k=4\n",
    "num_centroids = k\n",
    "\n",
    "# Initialise 'k' centroids (y1, .. yk) randomly from the data set\n",
    "centroids = dataset[np.random.randint(dataset.shape[0], size=num_centroids), :]\n",
    "print('Initial centroids\\n', centroids)\n",
    "\n",
    "\n",
    "# To only run K_means\n",
    "k_means = True\n",
    "k_medians = False\n",
    "\n",
    "# To only run K_medians\n",
    "# k_means = False\n",
    "# k_medians = True\n",
    "\n",
    "data = deepcopy(dataset)\n",
    "\n",
    "#### update centroids based on new cluster data\n",
    "\n",
    "for _ in range(100):\n",
    "    # if check_convergence():\n",
    "    #     break\n",
    "    num_centroids = k\n",
    "\n",
    "    # for the current iteration, get the centroids (index value) assigned to the corresponding datapoints index\n",
    "    clusters = group_data_to_cluster(num_centroids)\n",
    "    centroids = update_centroids(clusters, num_centroids)\n",
    "\n",
    "precision, recall, f_score = compute_metrics(num_centroids)\n",
    "print(precision)\n",
    "print(\"\\nKMeans Centroids from computed for k = 4:\")\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Output from SKLEARN\n",
      "[[-0.23340746 -0.0955901   0.07988927 ... -0.43806341 -0.06295059\n",
      "   0.05672025]\n",
      " [ 0.38627178  0.3143458   0.05909229 ...  0.09175967  0.11883498\n",
      "   0.25313992]\n",
      " [-0.10709906 -0.10474646 -0.06334103 ... -0.08248652 -0.23759206\n",
      "   0.13968116]\n",
      " [-0.07048999 -0.20060509 -0.26966388 ... -0.1941668   0.06881185\n",
      "   0.18472587]]\n"
     ]
    }
   ],
   "source": [
    "#### ******************* IGNORE CODE BELOW ********************\n",
    "\n",
    "#### TESTING THE CODE\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=k)\n",
    "model.fit(data)\n",
    "print(\"\\n\\nOutput from SKLEARN\")\n",
    "print(model.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   2.   3. ]\n",
      " [ 2.3  5.2  6. ]\n",
      " [ 9.  11.   7. ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.3, 5.2, 6. ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array([[1,2,3], \n",
    "              [2.3,5.2,6],\n",
    "              [9,11,7]])\n",
    "print(d)\n",
    "np.median(d, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 1 3 2 2 3 2 3]\n",
      "[5 6 5 4 5 6 5 5 4 7]\n"
     ]
    }
   ],
   "source": [
    "cat = np.array((1,2,3,1,3,2,2,3,2,3))\n",
    "print(cat)\n",
    "\n",
    "clust   = np.array((5,6,5,4,5,6,5,5,4,7))\n",
    "print(clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 1, 3, 2, 2, 3, 2, 3],\n",
       "       [5, 6, 5, 4, 5, 6, 5, 5, 4, 7]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb = np.vstack((cat, clust))\n",
    "print(comb.shape)\n",
    "comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(comb==2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 4])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 3 2 3]\n",
      "[False False False  True False]\n",
      "[2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = cat[clust==5]\n",
    "np.count_nonzero(mask[mask==2])\n",
    "np.count_nonzero(mask==2)\n",
    "\n",
    "print(mask)\n",
    "print(mask==2)\n",
    "print(mask[mask==2])\n",
    "\n",
    "np.count_nonzero(cat[clust==5]==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2 1.  0.6 0.5 0.6 1.  0.2 0.6 0.5 1. ]\n",
      "[0.5  0.5  0.75 0.5  0.75 0.5  0.25 0.75 0.25 0.25]\n",
      "[0.28571429 0.66666667 0.66666667 0.5        0.66666667 0.66666667\n",
      " 0.22222222 0.66666667 0.33333333 0.4       ]\n",
      "0.62\n",
      "0.5\n",
      "0.5074603174603174\n"
     ]
    }
   ],
   "source": [
    "len_data = len(clust)\n",
    "precision = np.zeros((len_data))\n",
    "recall = np.zeros((len_data))\n",
    "f_score = np.zeros((len_data))\n",
    "for i in range(len_data):\n",
    "    # get the count of the 'category' from it's assigned 'cluster'\n",
    "    category_in_cluster_count = np.count_nonzero(cat[clust == clust[i]] == cat[i])\n",
    "    # get the total count of datapoints belonging to the 'category' in the dataset\n",
    "    category_total_count = np.count_nonzero(cat==cat[i])\n",
    "    # get the count of datapoints assigned to the 'cluster'\n",
    "    cluster_elements_count = np.count_nonzero(clust == clust[i])\n",
    "#     count = np.sum(cat[clust==clust[i]]==cat[i])\n",
    "    # compute precision\n",
    "    precision[i] = category_in_cluster_count / cluster_elements_count\n",
    "    recall[i] = category_in_cluster_count / category_total_count\n",
    "#     f_score[i] = 2*precision[i]*recall[i]/(precision[i]+recall[i])\n",
    "#     print(f'Count of category {cat[i]} in cluster {clust[i]} = {category_in_cluster_count}')\n",
    "#     print(f'Count of category {cat[i]} in dataset = {category_total_count}')\n",
    "#     print(f'Total elements in cluster {clust[i]} = {cluster_elements_count}')\n",
    "f_score = 2*precision*recall/(precision+recall)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f_score)\n",
    "print(np.sum(precision)/len_data)\n",
    "print(np.sum(recall)/len_data)\n",
    "print(np.sum(f_score)/len_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 1 3 2 2 3 2 3]\n",
      "[5 6 5 4 5 6 5 5 4 7]\n"
     ]
    }
   ],
   "source": [
    "print(cat)\n",
    "print(clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of category 1 in cluster 5 = 1\n",
      "Count of category 2 in cluster 6 = 2\n",
      "Count of category 3 in cluster 5 = 3\n",
      "Count of category 1 in cluster 4 = 1\n",
      "Count of category 3 in cluster 5 = 3\n",
      "Count of category 2 in cluster 6 = 2\n",
      "Count of category 2 in cluster 5 = 1\n",
      "Count of category 3 in cluster 5 = 3\n",
      "Count of category 2 in cluster 4 = 1\n",
      "Count of category 3 in cluster 7 = 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    mask = cat[clust==clust[i]]\n",
    "#     count = np.count_nonzero(mask==cat[i])\n",
    "    count = np.count_nonzero((cat[clust==clust[i]]) == cat[i])\n",
    "    print(f'Count of category {cat[i]} in cluster {clust[i]} = {count}')\n",
    "# mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 5 but corresponding boolean dimension is 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9g/_31yc5b92m96cxdj9hkt6kd80000gn/T/ipykernel_2995/51572080.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclust\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 5 but corresponding boolean dimension is 10"
     ]
    }
   ],
   "source": [
    "cat[clust==5][cat==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb[(comb==5) | (comb==3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select only classes needed for classification\n",
    "# data = data[np.where((data[:,-1] == positive_class) | (data[:,-1] == negative_class))]\n",
    "\n",
    "# # converting class labels to numeric values [+1 or -1] based on the 1 v/s rest approach\n",
    "# data[data=='class-1'] = 1\n",
    "# data[(data=='class-2') | (data=='class-3')] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.array((0,0,1))==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "k-means-clustering.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
